#  마음 일기 분석

##  프로젝트 개요

개인의 일기 데이터를 LLM으로 심층 분석하고, 분석된 결과를 바탕으로 사용자 친화적인 RAG 기반의 질의응답 시스템을 구축합니다.

1.  감정 구조화: 비정형적인 일기 텍스트에서 감정 유형, 강도, 구체적인 원인 사건을 JSON 구조로 추출 및 분석합니다.
2.  종합 보고서 생성: 분석된 감정 데이터를 통합하여 심리 분석 보고서를 생성합니다.
3.  대화형 검색: 사용자가 자신의 일기 내용에 대해 직접 질문하고 답변을 얻는 RAG 시스템을 구축합니다.

---

## 기술 스택 및 환경 설정

### 1. 기술 스택

| 분류 | 기술 | 역할 |
| LLM | Google Gemini (2.5 Flash, Embedding-001) | 분석, 보고서 생성, 임베딩 벡터 생성 |
| 프레임워크 | LangChain | LLM 파이프라인(Chain) 및 RAG 구축 |
| 데이터베이스 | ChromaDB | 일기 청크의 벡터 저장 및 검색 |
| 데이터 구조 | Pydantic | LLM 출력의 구조와 유효성 검사 |
| 환경 관리 | Python, `python-dotenv` | 코드 실행 및 환경 변수 관리 |

### 2. 환경 설정

#### A. API 키 설정

1.  프로젝트 `.env` 파일 생성합니다.
2.  발급받은 **Gemini API 키**를 입력:
    ```env
    GEMINI_API_KEY="당신의 발급받은 실제 API 키"
    ```

#### B. 가상 환경 및 라이브러리 설치

1.  터미널에서 가상 환경(`venv`)을 생성하고 활성화합니다:
    $$RAG 테스트 생성시 Local 환경 오류 지속으로 가상 환경 활성화$$
    ```bash
    python -m venv venv
    .\venv\Scripts\activate
    ```
2.  활성화된 `(venv)` 환경에서 필수 라이브러리를 설치:
    ```bash
    python -m pip install -U langchain-google-genai langchain-community langchain-core pydantic python-dotenv chromadb
    ```

### C. 데이터 관리 및 보안 고지 (필수 확인)

본 프로젝트는 개인의 민감한 일기 데이터를 사용합니다. 따라서, 원본 RAW 데이터가 포함된 `data_raw/` 폴더 전체는 개인 정보 보호를 위해 `.gitignore` 처리.


## 프로젝트 실행 방법

1.  테어터 준비: 일기 데이터 파일을 `data_raw/my-diaries-7days.txt` 경로에 위치시킵니다.
2.  메인 실행: 가상 환경이 활성화된 상태에서 `main.py`를 실행:
    ```bash
    python main.py
    ```

### 실행 과정
$$Langchain Pipeline (청크분할 ->임배딩 ->LLM분석 ->RAG 테스트)$$
`main.py`를 실행 후 4단계로 진행

1.  데이터 로드 및 청크 분할: 일기 텍스트를 작은 단위(청크)로 나눔.
2.  일괄 감정 분석: 각 청크를 LLM이 분석하여 Pydantic 스키마에 맞는 JSON 보고서를 생성.
3.  종합 보고서 생성: JSON 분석 결과를 통합하여 최종 심리 보고서를 작.
4.  RAG 테스트: 일기 청크를 벡터 데이터베이스(ChromaDB)에 저장하고, 테스트 질문을 던져 답변을 검색.

---

## 주요 결과물

| 파일명 | 내용 | 설명 |
| `emotion-reports.json` | JSON 데이터 | 청크별 감정 태그, 강도, 원인 사건 등의 구조화된 분석 데이터 |
| `final-psychological-report.md` | 마크다운 파일 | LLM이 작성한 일주일간의 종합적인 심리 분석 및 평가 보고서 |
| 터미널 출력 | 텍스트 | RAG 시스템에 대한 테스트 질문과 답변 (예: "가장 기뻤던 사건과 날짜는?") |

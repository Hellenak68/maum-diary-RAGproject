# íŒŒì¼ ì´ë¦„: main.py (ì–¸ë”ë°” íŒŒì¼ë“¤ì„ ì„í¬íŠ¸)

import json
import time
from data_preparer import prepare_data # ì–¸ë”ë°” íŒŒì¼ì—ì„œ ì„í¬íŠ¸
from analysis_chains import get_emotion_analysis_chain, get_final_report_chain # ì–¸ë”ë°” íŒŒì¼ì—ì„œ ì„í¬íŠ¸
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEYë¥¼ .env íŒŒì¼ì— ì •í™•íˆ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

# ğŸŒŸğŸŒŸğŸŒŸ ì¶”ê°€í•  ì½”ë“œ ğŸŒŸğŸŒŸğŸŒŸ
# Google SDKê°€ ê¸°ë³¸ì ìœ¼ë¡œ ì°¾ëŠ” í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ì—ë„ í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
os.environ["GOOGLE_API_KEY"] = GEMINI_API_KEY 
# ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

def format_docs(docs):
    """RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    return "\n\n".join(doc.page_content for doc in docs)


def main():
    """ëª¨ë“  ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥/ì €ì¥í•©ë‹ˆë‹¤."""
    
    # 1. ë°ì´í„° ì¤€ë¹„ 
    print("1. ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    try:
        processed_documents = prepare_data()
    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return
        
    print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ. ì´ {len(processed_documents)}ê°œ ì²­í¬.")
    
    # 2. ë¶„ì„ ì²´ì¸ ë¡œë“œ 
    emotion_chain = get_emotion_analysis_chain()
    final_report_chain = get_final_report_chain()
    
    # 3. ì¼ê´„ ë¶„ì„
    print("\n2. ì¼ê´„ ê°ì • ë¶„ì„ ì‹œì‘...")
    all_analysis_reports = []
    
    for i, chunk in enumerate(processed_documents):
        try:
            # Pydantic Output Parserì˜ format_instructionsë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ ë³€ê²½
            analysis_result = emotion_chain.invoke(
                {
                    "diary_chunk": chunk.page_content,
                    "format_instructions": emotion_chain.steps[-1].get_format_instructions(), # íŒŒì„œì—ì„œ ëª…ë ¹ì–´ ê°€ì ¸ì˜¤ê¸°
                }
            )
            report_data = analysis_result.model_dump()
            report_data['metadata'] = chunk.metadata
            all_analysis_reports.append(report_data)
            print(f"  [+] ì²­í¬ {i+1} ë¶„ì„ ì™„ë£Œ.")
        except Exception as e:
            print(f"  [-] ì²­í¬ {i+1} ë¶„ì„ ì˜¤ë¥˜: {e}")
        time.sleep(1) 

    # 4. JSON ì €ì¥
    output_file_path = "./emotion-reports.json" # ì¶œë ¥ íŒŒì¼ì€ í•˜ì´í”ˆ ì‚¬ìš©
    with open(output_file_path, 'w', encoding='utf-8') as f:
        json.dump(all_analysis_reports, f, ensure_ascii=False, indent=4)
    print(f"âœ… ë¶„ì„ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_file_path}")

    
    # 5. ì¢…í•© ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥
    print("\n3. ì¢…í•© ì‹¬ë¦¬ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    reports_string = json.dumps(all_analysis_reports, ensure_ascii=False, indent=2)

    final_report = final_report_chain.invoke({"analysis_data": reports_string})
    report_content = final_report.content
    
    report_output_file = "final-psychological-report.md" # ì¶œë ¥ íŒŒì¼ì€ í•˜ì´í”ˆ ì‚¬ìš©
    with open(report_output_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    print(f"âœ… ì¢…í•© ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {report_output_file}")
    
    # 6. RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë° í…ŒìŠ¤íŠ¸
    print("\n4. RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ì´ ë¶€ë¶„ì€ main.py íŒŒì¼ ë§¨ ìœ„ì—ì„œ import ë˜ì—ˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # from dotenv import load_dotenv, os
    # load_dotenv()
    # GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

    # ğŸŒŸ ìˆ˜ì •ëœ ì½”ë“œ: embeddings ê°ì²´ ìƒì„± ì‹œ api_key ë³€ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001", 
        api_key=GEMINI_API_KEY # <-- í‚¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    )
    
    vectorstore = Chroma.from_documents(documents=processed_documents, embedding=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    # RAG ì²´ì¸ êµ¬ì¶•
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | final_report_chain 
    )
    
    test_question = "ë‚´ê°€ ì¼ì£¼ì¼ ë™ì•ˆ ê°€ì¥ ê¸°ë»¤ë˜ ì‚¬ê±´ì€ ë¬´ì—‡ì´ë©°, ê·¸ ë‚ ì§œëŠ” ì–¸ì œì•¼?"
    rag_response = rag_chain.invoke({"question": test_question})
    
    print(f"\n--- RAG ë‹µë³€ (ì§ˆë¬¸: {test_question}) ---")
    print(rag_response.content)
    print("------------------------------------------")
    
    vectorstore.delete_collection()
    print("âœ… RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ. ëª¨ë“ˆí™”ëœ í”„ë¡œì íŠ¸ ì™„ì„±!")


if __name__ == "__main__":
    main()